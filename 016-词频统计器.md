完整代码在 ./codes/016/016_wordsFreq.py



词频 = 某个词出现的次数 / 文章总词数

思路: 

1. 读入文章
2. 通过 jieba 将文章进行分词
3. 对每个词进行统计, 统计出现的次数
4. 按照出现次数进行排序, 取前几位的词计算词频

<img src="assets/image-20220812001118004.png" alt="image-20220812001118004" style="zoom: 50%;" />



###### 读入文章

```python
# 读取 ./news.txt 这个文件
with open("./news.txt", 'r', encoding="utf8") as txt_file:
    txt = txt_file.read()

# 对字符串进行预处理, 剔除换行符, 和制表符
txt = txt.replace("\n", '').replace('\u3000', '')
```



###### 通过 jieba 进行分词

```python
import jieba

words = jieba.cut(txt)  #PS: words 是一个生成器

```

